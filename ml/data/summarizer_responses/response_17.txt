der a commodity desktop environment, the QRNN
model is humanly indistinguishable from the KN-
5 model, even without using GPU acceleration.
5 Conclusion
In the present work, we describe and examine the
tradeoff space between quality and performance
for the task of language modeling. Speciﬁcally,
we explore the quality–performance tradeoffs be-
tween KN-5, a non-neural approach, and AWD-
LSTM and QRNN, two neural language mod-
els. We ﬁnd that with decreased perplexity comes