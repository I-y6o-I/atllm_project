{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42b20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uuid\n",
    "import json\n",
    "from typing import Optional, List, Dict, Any\n",
    "from qdrant_client import QdrantClient, models\n",
    "from sklearn.decomposition import PCA\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786ce7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Qdrant at localhost:6333\n",
      "Collections: ['raptor_collection', 'papers_collection']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1237777/4241095404.py:5: UserWarning: Qdrant client version 1.14.3 is incompatible with server version 1.16.2. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  qdrant = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n"
     ]
    }
   ],
   "source": [
    "QDRANT_HOST = \"localhost\"\n",
    "QDRANT_PORT = 6333\n",
    "COLLECTION_NAME = \"raptor_collection\"\n",
    "\n",
    "qdrant = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n",
    "print(f\"Connected to Qdrant at {QDRANT_HOST}:{QDRANT_PORT}\")\n",
    "print(f\"Collections: {[c.name for c in qdrant.get_collections().collections]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3f8573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/shared/miniconda3/envs/open-labs-share/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "print(\"Embedding model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d910cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_by_level(level: int, limit: int = 10000) -> List[Dict[str, Any]]:\n",
    "    results, _ = qdrant.scroll(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        scroll_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"metadata.level\",\n",
    "                    match=models.MatchValue(value=level)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "        with_vectors=True\n",
    "    )\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            \"node_id\": point.id,\n",
    "            \"text\": point.payload.get(\"text\", \"\"),\n",
    "            \"metadata\": point.payload.get(\"metadata\", {}),\n",
    "            \"vector\": point.vector\n",
    "        }\n",
    "        for point in results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87cc2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(embeddings: np.ndarray, n_components: int = 10) -> np.ndarray:\n",
    "    n_samples = embeddings.shape[0]\n",
    "    n_features = embeddings.shape[1]\n",
    "    \n",
    "    target_components = min(n_components, n_samples, n_features)\n",
    "    \n",
    "    if target_components < 2:\n",
    "        return embeddings\n",
    "    \n",
    "    pca = PCA(n_components=target_components)\n",
    "    return pca.fit_transform(embeddings)\n",
    "\n",
    "\n",
    "def cluster_embeddings_hdbscan(\n",
    "    embeddings: np.ndarray,\n",
    "    min_cluster_size: int = 5,\n",
    "    min_samples: int = 2,\n",
    "    reduce_dims: bool = True,\n",
    "    n_components: int = 50\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Cluster embeddings using HDBSCAN.\n",
    "    \n",
    "    HDBSCAN automatically determines the number of clusters and can identify noise points.\n",
    "    Noise points (label=-1) are assigned to their nearest cluster.\n",
    "    \"\"\"\n",
    "    n_samples = embeddings.shape[0]\n",
    "    \n",
    "    if n_samples < min_cluster_size:\n",
    "        return np.zeros(n_samples, dtype=int)\n",
    "    \n",
    "    if reduce_dims and embeddings.shape[1] > n_components:\n",
    "        reduced = reduce_dimensions(embeddings, n_components=min(n_components, n_samples - 1))\n",
    "    else:\n",
    "        reduced = embeddings\n",
    "    \n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=min_samples,\n",
    "        metric='euclidean',\n",
    "        cluster_selection_method='eom'\n",
    "    )\n",
    "    \n",
    "    labels = clusterer.fit_predict(reduced)\n",
    "    \n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1)\n",
    "    print(f\"HDBSCAN found {n_clusters} clusters, {n_noise} noise points\")\n",
    "    \n",
    "    if n_noise > 0 and n_clusters > 0:\n",
    "        labels = assign_noise_to_nearest_cluster(reduced, labels)\n",
    "    elif n_clusters == 0:\n",
    "        print(\"No clusters found, treating all as one cluster\")\n",
    "        return np.zeros(n_samples, dtype=int)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def assign_noise_to_nearest_cluster(embeddings: np.ndarray, labels: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Assign noise points (label=-1) to their nearest cluster centroid.\"\"\"\n",
    "    labels = labels.copy()\n",
    "    \n",
    "    unique_clusters = [l for l in set(labels) if l != -1]\n",
    "    \n",
    "    centroids = {}\n",
    "    for cluster_id in unique_clusters:\n",
    "        cluster_mask = labels == cluster_id\n",
    "        centroids[cluster_id] = embeddings[cluster_mask].mean(axis=0)\n",
    "    \n",
    "    noise_indices = np.where(labels == -1)[0]\n",
    "    \n",
    "    for idx in noise_indices:\n",
    "        point = embeddings[idx]\n",
    "        min_dist = float('inf')\n",
    "        nearest_cluster = unique_clusters[0]\n",
    "        \n",
    "        for cluster_id, centroid in centroids.items():\n",
    "            dist = np.linalg.norm(point - centroid)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                nearest_cluster = cluster_id\n",
    "        \n",
    "        labels[idx] = nearest_cluster\n",
    "    \n",
    "    print(f\"Reassigned {len(noise_indices)} noise points to nearest clusters\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "def group_nodes_by_cluster(nodes: List[Dict], labels: np.ndarray) -> Dict[int, List[Dict]]:\n",
    "    groups = {}\n",
    "    for node, label in zip(nodes, labels):\n",
    "        label_int = int(label)\n",
    "        if label_int not in groups:\n",
    "            groups[label_int] = []\n",
    "        groups[label_int].append(node)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e46f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_summarize(texts: List[str]) -> str:\n",
    "    \"\"\"Mock summarizer - just concatenates first 500 chars of each text.\"\"\"\n",
    "    combined = \" \".join([t[:200] for t in texts[:3]])\n",
    "    return f\"[MOCK SUMMARY] {combined[:500]}...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63161e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_storage = {\n",
    "    \"levels\": {},\n",
    "    \"parent_child_map\": {},\n",
    "    \"stats\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96453f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 level 0 nodes in Qdrant\n"
     ]
    }
   ],
   "source": [
    "level0_nodes = get_nodes_by_level(0)\n",
    "print(f\"Found {len(level0_nodes)} level 0 nodes in Qdrant\")\n",
    "\n",
    "tree_storage[\"levels\"][0] = level0_nodes\n",
    "tree_storage[\"stats\"][0] = {\n",
    "    \"count\": len(level0_nodes),\n",
    "    \"node_type\": \"chunk\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a97669af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample Level 0 Node ---\n",
      "Node ID: 0000b40c-138b-4d17-8b15-9e22432ee915\n",
      "Text (first 300 chars): Medium : statement that accomplishes one of\n",
      "these elements. (iii)High : statement that clearly\n",
      "accomplishes at least two speciﬁcity elements.\n",
      "Even though we do not explicitly use labels\n",
      "for the four speciﬁcity elements, we found that\n",
      "explicitly breaking down speciﬁcity into multiple\n",
      "components helpe...\n",
      "Metadata: {\n",
      "  \"filename\": \"64/article.pdf\",\n",
      "  \"paper_id\": \"64\",\n",
      "  \"level\": 0,\n",
      "  \"node_type\": \"chunk\",\n",
      "  \"node_id\": \"0000b40c-138b-4d17-8b15-9e22432ee915\",\n",
      "  \"children_ids\": [],\n",
      "  \"parent_ids\": [],\n",
      "  \"cluster_id\": null,\n",
      "  \"chunk_index\": 23,\n",
      "  \"total_chunks\": 47,\n",
      "  \"token_count\": 121\n",
      "}\n",
      "Vector shape: (384,)\n"
     ]
    }
   ],
   "source": [
    "if level0_nodes:\n",
    "    print(\"\\n--- Sample Level 0 Node ---\")\n",
    "    sample = level0_nodes[0]\n",
    "    print(f\"Node ID: {sample['node_id']}\")\n",
    "    print(f\"Text (first 300 chars): {sample['text'][:300]}...\")\n",
    "    print(f\"Metadata: {json.dumps(sample['metadata'], indent=2)}\")\n",
    "    print(f\"Vector shape: {np.array(sample['vector']).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8853722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_next_level_local(\n",
    "    current_nodes: List[Dict],\n",
    "    current_level: int,\n",
    "    summarize_fn,\n",
    "    min_cluster_size: int = 5\n",
    ") -> Dict[str, Any]:\n",
    "    \n",
    "    if len(current_nodes) < min_cluster_size:\n",
    "        print(f\"Not enough nodes ({len(current_nodes)}) to cluster\")\n",
    "        return {\n",
    "            \"level\": current_level + 1,\n",
    "            \"nodes\": [],\n",
    "            \"stopped\": True,\n",
    "            \"reason\": \"insufficient_nodes\"\n",
    "        }\n",
    "    \n",
    "    embeddings = np.array([node[\"vector\"] for node in current_nodes])\n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "    \n",
    "    labels = cluster_embeddings_hdbscan(\n",
    "        embeddings,\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=2\n",
    "    )\n",
    "    n_clusters = len(set(labels))\n",
    "    print(f\"Final cluster count: {n_clusters}\")\n",
    "    \n",
    "    groups = group_nodes_by_cluster(current_nodes, labels)\n",
    "    \n",
    "    print(f\"\\nCluster sizes:\")\n",
    "    for cluster_id, nodes in groups.items():\n",
    "        print(f\"  Cluster {cluster_id}: {len(nodes)} nodes\")\n",
    "    \n",
    "    next_level = current_level + 1\n",
    "    new_nodes = []\n",
    "    parent_child_map = {}\n",
    "    \n",
    "    for cluster_id, cluster_nodes in groups.items():\n",
    "        texts = [node[\"text\"] for node in cluster_nodes]\n",
    "        children_ids = [node[\"node_id\"] for node in cluster_nodes]\n",
    "        \n",
    "        summary = summarize_fn(texts)\n",
    "        \n",
    "        summary_embedding = embedding_model.embed_query(summary)\n",
    "        \n",
    "        node_id = str(uuid.uuid4())\n",
    "        \n",
    "        new_node = {\n",
    "            \"node_id\": node_id,\n",
    "            \"text\": summary,\n",
    "            \"vector\": summary_embedding,\n",
    "            \"metadata\": {\n",
    "                \"level\": next_level,\n",
    "                \"node_type\": \"summary\",\n",
    "                \"children_ids\": children_ids,\n",
    "                \"parent_ids\": [],\n",
    "                \"cluster_id\": int(cluster_id),\n",
    "                \"children_count\": len(children_ids),\n",
    "                \"token_count\": len(summary) // 4,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        new_nodes.append(new_node)\n",
    "        parent_child_map[node_id] = children_ids\n",
    "    \n",
    "    print(f\"\\nBuilt {len(new_nodes)} summary nodes for level {next_level}\")\n",
    "    \n",
    "    return {\n",
    "        \"level\": next_level,\n",
    "        \"nodes\": new_nodes,\n",
    "        \"parent_child_map\": parent_child_map,\n",
    "        \"stopped\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae67cc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Building Level 1 from Level 0\n",
      "==================================================\n",
      "Embeddings shape: (10000, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/shared/miniconda3/envs/open-labs-share/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/mnt/shared/miniconda3/envs/open-labs-share/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDBSCAN found 199 clusters, 7756 noise points\n",
      "Reassigned 7756 noise points to nearest clusters\n",
      "Final cluster count: 199\n",
      "\n",
      "Cluster sizes:\n",
      "  Cluster 10: 37 nodes\n",
      "  Cluster 138: 92 nodes\n",
      "  Cluster 95: 40 nodes\n",
      "  Cluster 145: 69 nodes\n",
      "  Cluster 137: 107 nodes\n",
      "  Cluster 119: 57 nodes\n",
      "  Cluster 157: 46 nodes\n",
      "  Cluster 0: 17 nodes\n",
      "  Cluster 128: 39 nodes\n",
      "  Cluster 163: 49 nodes\n",
      "  Cluster 42: 61 nodes\n",
      "  Cluster 156: 51 nodes\n",
      "  Cluster 170: 122 nodes\n",
      "  Cluster 19: 61 nodes\n",
      "  Cluster 60: 161 nodes\n",
      "  Cluster 139: 257 nodes\n",
      "  Cluster 125: 138 nodes\n",
      "  Cluster 44: 72 nodes\n",
      "  Cluster 55: 29 nodes\n",
      "  Cluster 165: 140 nodes\n",
      "  Cluster 173: 148 nodes\n",
      "  Cluster 191: 59 nodes\n",
      "  Cluster 182: 118 nodes\n",
      "  Cluster 121: 19 nodes\n",
      "  Cluster 198: 52 nodes\n",
      "  Cluster 164: 27 nodes\n",
      "  Cluster 150: 25 nodes\n",
      "  Cluster 91: 39 nodes\n",
      "  Cluster 195: 146 nodes\n",
      "  Cluster 77: 46 nodes\n",
      "  Cluster 78: 55 nodes\n",
      "  Cluster 68: 46 nodes\n",
      "  Cluster 106: 22 nodes\n",
      "  Cluster 146: 48 nodes\n",
      "  Cluster 58: 46 nodes\n",
      "  Cluster 123: 110 nodes\n",
      "  Cluster 168: 51 nodes\n",
      "  Cluster 5: 86 nodes\n",
      "  Cluster 180: 37 nodes\n",
      "  Cluster 176: 53 nodes\n",
      "  Cluster 90: 38 nodes\n",
      "  Cluster 35: 46 nodes\n",
      "  Cluster 181: 82 nodes\n",
      "  Cluster 144: 41 nodes\n",
      "  Cluster 25: 50 nodes\n",
      "  Cluster 22: 40 nodes\n",
      "  Cluster 132: 48 nodes\n",
      "  Cluster 66: 43 nodes\n",
      "  Cluster 107: 41 nodes\n",
      "  Cluster 14: 14 nodes\n",
      "  Cluster 187: 91 nodes\n",
      "  Cluster 48: 36 nodes\n",
      "  Cluster 162: 106 nodes\n",
      "  Cluster 67: 21 nodes\n",
      "  Cluster 172: 68 nodes\n",
      "  Cluster 24: 13 nodes\n",
      "  Cluster 127: 49 nodes\n",
      "  Cluster 96: 57 nodes\n",
      "  Cluster 147: 31 nodes\n",
      "  Cluster 20: 95 nodes\n",
      "  Cluster 11: 130 nodes\n",
      "  Cluster 51: 181 nodes\n",
      "  Cluster 175: 38 nodes\n",
      "  Cluster 116: 55 nodes\n",
      "  Cluster 82: 55 nodes\n",
      "  Cluster 152: 61 nodes\n",
      "  Cluster 84: 52 nodes\n",
      "  Cluster 15: 66 nodes\n",
      "  Cluster 171: 65 nodes\n",
      "  Cluster 89: 12 nodes\n",
      "  Cluster 70: 99 nodes\n",
      "  Cluster 69: 49 nodes\n",
      "  Cluster 190: 52 nodes\n",
      "  Cluster 39: 101 nodes\n",
      "  Cluster 83: 102 nodes\n",
      "  Cluster 80: 57 nodes\n",
      "  Cluster 75: 65 nodes\n",
      "  Cluster 53: 24 nodes\n",
      "  Cluster 52: 23 nodes\n",
      "  Cluster 104: 56 nodes\n",
      "  Cluster 29: 156 nodes\n",
      "  Cluster 32: 73 nodes\n",
      "  Cluster 178: 55 nodes\n",
      "  Cluster 122: 19 nodes\n",
      "  Cluster 100: 74 nodes\n",
      "  Cluster 114: 78 nodes\n",
      "  Cluster 124: 107 nodes\n",
      "  Cluster 184: 75 nodes\n",
      "  Cluster 193: 36 nodes\n",
      "  Cluster 61: 67 nodes\n",
      "  Cluster 86: 63 nodes\n",
      "  Cluster 149: 69 nodes\n",
      "  Cluster 105: 113 nodes\n",
      "  Cluster 155: 49 nodes\n",
      "  Cluster 40: 78 nodes\n",
      "  Cluster 38: 36 nodes\n",
      "  Cluster 45: 31 nodes\n",
      "  Cluster 134: 36 nodes\n",
      "  Cluster 135: 22 nodes\n",
      "  Cluster 59: 18 nodes\n",
      "  Cluster 140: 19 nodes\n",
      "  Cluster 101: 113 nodes\n",
      "  Cluster 169: 42 nodes\n",
      "  Cluster 148: 103 nodes\n",
      "  Cluster 73: 50 nodes\n",
      "  Cluster 65: 107 nodes\n",
      "  Cluster 18: 97 nodes\n",
      "  Cluster 31: 41 nodes\n",
      "  Cluster 154: 92 nodes\n",
      "  Cluster 120: 33 nodes\n",
      "  Cluster 1: 6 nodes\n",
      "  Cluster 71: 22 nodes\n",
      "  Cluster 21: 13 nodes\n",
      "  Cluster 85: 33 nodes\n",
      "  Cluster 179: 31 nodes\n",
      "  Cluster 81: 63 nodes\n",
      "  Cluster 8: 46 nodes\n",
      "  Cluster 110: 36 nodes\n",
      "  Cluster 160: 7 nodes\n",
      "  Cluster 115: 35 nodes\n",
      "  Cluster 88: 18 nodes\n",
      "  Cluster 129: 14 nodes\n",
      "  Cluster 23: 9 nodes\n",
      "  Cluster 109: 28 nodes\n",
      "  Cluster 93: 34 nodes\n",
      "  Cluster 41: 26 nodes\n",
      "  Cluster 131: 35 nodes\n",
      "  Cluster 49: 35 nodes\n",
      "  Cluster 151: 46 nodes\n",
      "  Cluster 43: 53 nodes\n",
      "  Cluster 113: 70 nodes\n",
      "  Cluster 6: 27 nodes\n",
      "  Cluster 63: 23 nodes\n",
      "  Cluster 16: 22 nodes\n",
      "  Cluster 197: 38 nodes\n",
      "  Cluster 72: 37 nodes\n",
      "  Cluster 136: 60 nodes\n",
      "  Cluster 111: 60 nodes\n",
      "  Cluster 57: 60 nodes\n",
      "  Cluster 102: 40 nodes\n",
      "  Cluster 94: 41 nodes\n",
      "  Cluster 167: 47 nodes\n",
      "  Cluster 56: 35 nodes\n",
      "  Cluster 186: 24 nodes\n",
      "  Cluster 26: 14 nodes\n",
      "  Cluster 112: 47 nodes\n",
      "  Cluster 126: 15 nodes\n",
      "  Cluster 133: 42 nodes\n",
      "  Cluster 79: 26 nodes\n",
      "  Cluster 189: 17 nodes\n",
      "  Cluster 34: 48 nodes\n",
      "  Cluster 141: 31 nodes\n",
      "  Cluster 185: 43 nodes\n",
      "  Cluster 103: 19 nodes\n",
      "  Cluster 142: 51 nodes\n",
      "  Cluster 118: 34 nodes\n",
      "  Cluster 64: 14 nodes\n",
      "  Cluster 37: 13 nodes\n",
      "  Cluster 12: 12 nodes\n",
      "  Cluster 9: 24 nodes\n",
      "  Cluster 99: 22 nodes\n",
      "  Cluster 161: 14 nodes\n",
      "  Cluster 62: 20 nodes\n",
      "  Cluster 28: 52 nodes\n",
      "  Cluster 17: 32 nodes\n",
      "  Cluster 130: 18 nodes\n",
      "  Cluster 33: 72 nodes\n",
      "  Cluster 30: 37 nodes\n",
      "  Cluster 50: 20 nodes\n",
      "  Cluster 97: 26 nodes\n",
      "  Cluster 159: 22 nodes\n",
      "  Cluster 54: 105 nodes\n",
      "  Cluster 92: 40 nodes\n",
      "  Cluster 36: 33 nodes\n",
      "  Cluster 3: 24 nodes\n",
      "  Cluster 2: 6 nodes\n",
      "  Cluster 47: 10 nodes\n",
      "  Cluster 194: 67 nodes\n",
      "  Cluster 158: 48 nodes\n",
      "  Cluster 108: 17 nodes\n",
      "  Cluster 192: 28 nodes\n",
      "  Cluster 7: 28 nodes\n",
      "  Cluster 13: 37 nodes\n",
      "  Cluster 196: 20 nodes\n",
      "  Cluster 87: 40 nodes\n",
      "  Cluster 188: 24 nodes\n",
      "  Cluster 166: 24 nodes\n",
      "  Cluster 46: 51 nodes\n",
      "  Cluster 174: 34 nodes\n",
      "  Cluster 27: 9 nodes\n",
      "  Cluster 143: 28 nodes\n",
      "  Cluster 76: 18 nodes\n",
      "  Cluster 98: 43 nodes\n",
      "  Cluster 117: 38 nodes\n",
      "  Cluster 153: 23 nodes\n",
      "  Cluster 74: 27 nodes\n",
      "  Cluster 177: 6 nodes\n",
      "  Cluster 183: 21 nodes\n",
      "  Cluster 4: 9 nodes\n",
      "Reassigned 7756 noise points to nearest clusters\n",
      "Final cluster count: 199\n",
      "\n",
      "Cluster sizes:\n",
      "  Cluster 10: 37 nodes\n",
      "  Cluster 138: 92 nodes\n",
      "  Cluster 95: 40 nodes\n",
      "  Cluster 145: 69 nodes\n",
      "  Cluster 137: 107 nodes\n",
      "  Cluster 119: 57 nodes\n",
      "  Cluster 157: 46 nodes\n",
      "  Cluster 0: 17 nodes\n",
      "  Cluster 128: 39 nodes\n",
      "  Cluster 163: 49 nodes\n",
      "  Cluster 42: 61 nodes\n",
      "  Cluster 156: 51 nodes\n",
      "  Cluster 170: 122 nodes\n",
      "  Cluster 19: 61 nodes\n",
      "  Cluster 60: 161 nodes\n",
      "  Cluster 139: 257 nodes\n",
      "  Cluster 125: 138 nodes\n",
      "  Cluster 44: 72 nodes\n",
      "  Cluster 55: 29 nodes\n",
      "  Cluster 165: 140 nodes\n",
      "  Cluster 173: 148 nodes\n",
      "  Cluster 191: 59 nodes\n",
      "  Cluster 182: 118 nodes\n",
      "  Cluster 121: 19 nodes\n",
      "  Cluster 198: 52 nodes\n",
      "  Cluster 164: 27 nodes\n",
      "  Cluster 150: 25 nodes\n",
      "  Cluster 91: 39 nodes\n",
      "  Cluster 195: 146 nodes\n",
      "  Cluster 77: 46 nodes\n",
      "  Cluster 78: 55 nodes\n",
      "  Cluster 68: 46 nodes\n",
      "  Cluster 106: 22 nodes\n",
      "  Cluster 146: 48 nodes\n",
      "  Cluster 58: 46 nodes\n",
      "  Cluster 123: 110 nodes\n",
      "  Cluster 168: 51 nodes\n",
      "  Cluster 5: 86 nodes\n",
      "  Cluster 180: 37 nodes\n",
      "  Cluster 176: 53 nodes\n",
      "  Cluster 90: 38 nodes\n",
      "  Cluster 35: 46 nodes\n",
      "  Cluster 181: 82 nodes\n",
      "  Cluster 144: 41 nodes\n",
      "  Cluster 25: 50 nodes\n",
      "  Cluster 22: 40 nodes\n",
      "  Cluster 132: 48 nodes\n",
      "  Cluster 66: 43 nodes\n",
      "  Cluster 107: 41 nodes\n",
      "  Cluster 14: 14 nodes\n",
      "  Cluster 187: 91 nodes\n",
      "  Cluster 48: 36 nodes\n",
      "  Cluster 162: 106 nodes\n",
      "  Cluster 67: 21 nodes\n",
      "  Cluster 172: 68 nodes\n",
      "  Cluster 24: 13 nodes\n",
      "  Cluster 127: 49 nodes\n",
      "  Cluster 96: 57 nodes\n",
      "  Cluster 147: 31 nodes\n",
      "  Cluster 20: 95 nodes\n",
      "  Cluster 11: 130 nodes\n",
      "  Cluster 51: 181 nodes\n",
      "  Cluster 175: 38 nodes\n",
      "  Cluster 116: 55 nodes\n",
      "  Cluster 82: 55 nodes\n",
      "  Cluster 152: 61 nodes\n",
      "  Cluster 84: 52 nodes\n",
      "  Cluster 15: 66 nodes\n",
      "  Cluster 171: 65 nodes\n",
      "  Cluster 89: 12 nodes\n",
      "  Cluster 70: 99 nodes\n",
      "  Cluster 69: 49 nodes\n",
      "  Cluster 190: 52 nodes\n",
      "  Cluster 39: 101 nodes\n",
      "  Cluster 83: 102 nodes\n",
      "  Cluster 80: 57 nodes\n",
      "  Cluster 75: 65 nodes\n",
      "  Cluster 53: 24 nodes\n",
      "  Cluster 52: 23 nodes\n",
      "  Cluster 104: 56 nodes\n",
      "  Cluster 29: 156 nodes\n",
      "  Cluster 32: 73 nodes\n",
      "  Cluster 178: 55 nodes\n",
      "  Cluster 122: 19 nodes\n",
      "  Cluster 100: 74 nodes\n",
      "  Cluster 114: 78 nodes\n",
      "  Cluster 124: 107 nodes\n",
      "  Cluster 184: 75 nodes\n",
      "  Cluster 193: 36 nodes\n",
      "  Cluster 61: 67 nodes\n",
      "  Cluster 86: 63 nodes\n",
      "  Cluster 149: 69 nodes\n",
      "  Cluster 105: 113 nodes\n",
      "  Cluster 155: 49 nodes\n",
      "  Cluster 40: 78 nodes\n",
      "  Cluster 38: 36 nodes\n",
      "  Cluster 45: 31 nodes\n",
      "  Cluster 134: 36 nodes\n",
      "  Cluster 135: 22 nodes\n",
      "  Cluster 59: 18 nodes\n",
      "  Cluster 140: 19 nodes\n",
      "  Cluster 101: 113 nodes\n",
      "  Cluster 169: 42 nodes\n",
      "  Cluster 148: 103 nodes\n",
      "  Cluster 73: 50 nodes\n",
      "  Cluster 65: 107 nodes\n",
      "  Cluster 18: 97 nodes\n",
      "  Cluster 31: 41 nodes\n",
      "  Cluster 154: 92 nodes\n",
      "  Cluster 120: 33 nodes\n",
      "  Cluster 1: 6 nodes\n",
      "  Cluster 71: 22 nodes\n",
      "  Cluster 21: 13 nodes\n",
      "  Cluster 85: 33 nodes\n",
      "  Cluster 179: 31 nodes\n",
      "  Cluster 81: 63 nodes\n",
      "  Cluster 8: 46 nodes\n",
      "  Cluster 110: 36 nodes\n",
      "  Cluster 160: 7 nodes\n",
      "  Cluster 115: 35 nodes\n",
      "  Cluster 88: 18 nodes\n",
      "  Cluster 129: 14 nodes\n",
      "  Cluster 23: 9 nodes\n",
      "  Cluster 109: 28 nodes\n",
      "  Cluster 93: 34 nodes\n",
      "  Cluster 41: 26 nodes\n",
      "  Cluster 131: 35 nodes\n",
      "  Cluster 49: 35 nodes\n",
      "  Cluster 151: 46 nodes\n",
      "  Cluster 43: 53 nodes\n",
      "  Cluster 113: 70 nodes\n",
      "  Cluster 6: 27 nodes\n",
      "  Cluster 63: 23 nodes\n",
      "  Cluster 16: 22 nodes\n",
      "  Cluster 197: 38 nodes\n",
      "  Cluster 72: 37 nodes\n",
      "  Cluster 136: 60 nodes\n",
      "  Cluster 111: 60 nodes\n",
      "  Cluster 57: 60 nodes\n",
      "  Cluster 102: 40 nodes\n",
      "  Cluster 94: 41 nodes\n",
      "  Cluster 167: 47 nodes\n",
      "  Cluster 56: 35 nodes\n",
      "  Cluster 186: 24 nodes\n",
      "  Cluster 26: 14 nodes\n",
      "  Cluster 112: 47 nodes\n",
      "  Cluster 126: 15 nodes\n",
      "  Cluster 133: 42 nodes\n",
      "  Cluster 79: 26 nodes\n",
      "  Cluster 189: 17 nodes\n",
      "  Cluster 34: 48 nodes\n",
      "  Cluster 141: 31 nodes\n",
      "  Cluster 185: 43 nodes\n",
      "  Cluster 103: 19 nodes\n",
      "  Cluster 142: 51 nodes\n",
      "  Cluster 118: 34 nodes\n",
      "  Cluster 64: 14 nodes\n",
      "  Cluster 37: 13 nodes\n",
      "  Cluster 12: 12 nodes\n",
      "  Cluster 9: 24 nodes\n",
      "  Cluster 99: 22 nodes\n",
      "  Cluster 161: 14 nodes\n",
      "  Cluster 62: 20 nodes\n",
      "  Cluster 28: 52 nodes\n",
      "  Cluster 17: 32 nodes\n",
      "  Cluster 130: 18 nodes\n",
      "  Cluster 33: 72 nodes\n",
      "  Cluster 30: 37 nodes\n",
      "  Cluster 50: 20 nodes\n",
      "  Cluster 97: 26 nodes\n",
      "  Cluster 159: 22 nodes\n",
      "  Cluster 54: 105 nodes\n",
      "  Cluster 92: 40 nodes\n",
      "  Cluster 36: 33 nodes\n",
      "  Cluster 3: 24 nodes\n",
      "  Cluster 2: 6 nodes\n",
      "  Cluster 47: 10 nodes\n",
      "  Cluster 194: 67 nodes\n",
      "  Cluster 158: 48 nodes\n",
      "  Cluster 108: 17 nodes\n",
      "  Cluster 192: 28 nodes\n",
      "  Cluster 7: 28 nodes\n",
      "  Cluster 13: 37 nodes\n",
      "  Cluster 196: 20 nodes\n",
      "  Cluster 87: 40 nodes\n",
      "  Cluster 188: 24 nodes\n",
      "  Cluster 166: 24 nodes\n",
      "  Cluster 46: 51 nodes\n",
      "  Cluster 174: 34 nodes\n",
      "  Cluster 27: 9 nodes\n",
      "  Cluster 143: 28 nodes\n",
      "  Cluster 76: 18 nodes\n",
      "  Cluster 98: 43 nodes\n",
      "  Cluster 117: 38 nodes\n",
      "  Cluster 153: 23 nodes\n",
      "  Cluster 74: 27 nodes\n",
      "  Cluster 177: 6 nodes\n",
      "  Cluster 183: 21 nodes\n",
      "  Cluster 4: 9 nodes\n",
      "\n",
      "Built 199 summary nodes for level 1\n",
      "\n",
      "Built 199 summary nodes for level 1\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Building Level 1 from Level 0\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result_level1 = build_next_level_local(\n",
    "    current_nodes=tree_storage[\"levels\"][0],\n",
    "    current_level=0,\n",
    "    summarize_fn=mock_summarize,\n",
    ")\n",
    "\n",
    "if not result_level1[\"stopped\"]:\n",
    "    tree_storage[\"levels\"][1] = result_level1[\"nodes\"]\n",
    "    tree_storage[\"parent_child_map\"].update(result_level1[\"parent_child_map\"])\n",
    "    tree_storage[\"stats\"][1] = {\n",
    "        \"count\": len(result_level1[\"nodes\"]),\n",
    "        \"node_type\": \"summary\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 in tree_storage[\"levels\"] and tree_storage[\"levels\"][1]:\n",
    "    print(\"\\n--- Sample Level 1 Node ---\")\n",
    "    sample = tree_storage[\"levels\"][1][0]\n",
    "    print(f\"Node ID: {sample['node_id']}\")\n",
    "    print(f\"Summary: {sample['text'][:500]}\")\n",
    "    print(f\"Children count: {sample['metadata']['children_count']}\")\n",
    "    print(f\"Children IDs: {sample['metadata']['children_ids'][:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 in tree_storage[\"levels\"] and len(tree_storage[\"levels\"][1]) >= 3:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Building Level 2 from Level 1\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    result_level2 = build_next_level_local(\n",
    "        current_nodes=tree_storage[\"levels\"][1],\n",
    "        current_level=1,\n",
    "        summarize_fn=mock_summarize\n",
    "    )\n",
    "    \n",
    "    if not result_level2[\"stopped\"]:\n",
    "        tree_storage[\"levels\"][2] = result_level2[\"nodes\"]\n",
    "        tree_storage[\"parent_child_map\"].update(result_level2[\"parent_child_map\"])\n",
    "        tree_storage[\"stats\"][2] = {\n",
    "            \"count\": len(result_level2[\"nodes\"]),\n",
    "            \"node_type\": \"summary\"\n",
    "        }\n",
    "else:\n",
    "    print(\"Not enough level 1 nodes to build level 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e86525",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2 in tree_storage[\"levels\"] and len(tree_storage[\"levels\"][2]) >= 3:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Building Level 3 from Level 2\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    result_level3 = build_next_level_local(\n",
    "        current_nodes=tree_storage[\"levels\"][2],\n",
    "        current_level=2,\n",
    "        summarize_fn=mock_summarize\n",
    "    )\n",
    "    \n",
    "    if not result_level3[\"stopped\"]:\n",
    "        tree_storage[\"levels\"][3] = result_level3[\"nodes\"]\n",
    "        tree_storage[\"parent_child_map\"].update(result_level3[\"parent_child_map\"])\n",
    "        tree_storage[\"stats\"][3] = {\n",
    "            \"count\": len(result_level3[\"nodes\"]),\n",
    "            \"node_type\": \"summary\"\n",
    "        }\n",
    "else:\n",
    "    print(\"Not enough level 2 nodes to build level 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d65dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL TREE STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_nodes = 0\n",
    "for level, stats in tree_storage[\"stats\"].items():\n",
    "    print(f\"Level {level}: {stats['count']} nodes ({stats['node_type']})\")\n",
    "    total_nodes += stats['count']\n",
    "\n",
    "print(f\"\\nTotal nodes: {total_nodes}\")\n",
    "print(f\"Max level: {max(tree_storage['stats'].keys())}\")\n",
    "print(f\"Parent-child relationships: {len(tree_storage['parent_child_map'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11449e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tree_sample(storage: Dict, max_children: int = 3):\n",
    "    \"\"\"Visualize a sample branch of the tree.\"\"\"\n",
    "    max_level = max(storage[\"levels\"].keys())\n",
    "    \n",
    "    if max_level == 0:\n",
    "        print(\"Only level 0 exists, no tree structure to visualize\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"SAMPLE TREE BRANCH\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    top_node = storage[\"levels\"][max_level][0]\n",
    "    \n",
    "    def print_node(node, indent=0):\n",
    "        prefix = \"  \" * indent\n",
    "        level = node[\"metadata\"][\"level\"]\n",
    "        node_type = node[\"metadata\"][\"node_type\"]\n",
    "        text_preview = node[\"text\"][:80].replace(\"\\n\", \" \")\n",
    "        print(f\"{prefix}[L{level}:{node_type}] {text_preview}...\")\n",
    "        \n",
    "        if \"children_ids\" in node[\"metadata\"] and node[\"metadata\"][\"children_ids\"]:\n",
    "            children_ids = node[\"metadata\"][\"children_ids\"][:max_children]\n",
    "            child_level = level - 1\n",
    "            \n",
    "            if child_level in storage[\"levels\"]:\n",
    "                for child_id in children_ids:\n",
    "                    child_node = next(\n",
    "                        (n for n in storage[\"levels\"][child_level] if n[\"node_id\"] == child_id),\n",
    "                        None\n",
    "                    )\n",
    "                    if child_node:\n",
    "                        print_node(child_node, indent + 1)\n",
    "    \n",
    "    print_node(top_node)\n",
    "\n",
    "visualize_tree_sample(tree_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/test_tree_storage.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tree_storage, f)\n",
    "\n",
    "print(\"Tree storage saved to data/test_tree_storage.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload and verify\n",
    "with open(\"data/test_tree_storage.pkl\", \"rb\") as f:\n",
    "    loaded_storage = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded tree with {len(loaded_storage['levels'])} levels\")\n",
    "print(f\"Stats: {loaded_storage['stats']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-labs-share",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
