2018a). A quasi-recurrent layer comprises two
separate parts: a convolution layer with threeweights, and a recurrent pooling layer. Given an
inputX2Rkn, the convolution layer is
Z= tanh( WzX)
F=(WfX)
O=(WoX)
wheredenotes the sigmoid function, represents
masked convolution across time, and Wfz;f;og2
Rmkrare convolution weights with kinput
channels,moutput channels, and a window size
ofr. In the recurrent pooling layer, the convolu-
tion outputs are combined sequentially: